{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8b9fca5-5e2e-4355-9619-3f93920d3d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb9cb224-da0a-4f84-b4e4-54882a032a25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.24.4)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: torchmetrics in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>1.20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchmetrics) (1.24.4)\n",
      "Requirement already satisfied: torch>=1.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchmetrics) (2.0.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchmetrics) (0.9.0)\n",
      "Requirement already satisfied: packaging>=17.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (21.3)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.7.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.12.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=17.1->lightning-utilities>=0.8.0->torchmetrics) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: statsmodels in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.18 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from statsmodels) (1.24.4)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from statsmodels) (1.11.1)\n",
      "Requirement already satisfied: pandas>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from statsmodels) (1.5.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from statsmodels) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=21.3->statsmodels) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas>=1.0->statsmodels) (2023.3)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.11.1)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scipy) (1.24.4)\n",
      "Requirement already satisfied: GPUtil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.4.0)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement gc (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for gc\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install scikit-learn\n",
    "!{sys.executable} -m pip install torch\n",
    "!{sys.executable} -m pip install torchmetrics\n",
    "!{sys.executable} -m pip install statsmodels\n",
    "!{sys.executable} -m pip install scipy\n",
    "!{sys.executable} -m pip install GPUtil\n",
    "!{sys.executable} -m pip install gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "920344b8-f0a4-4aea-b3a8-9f32bb94c798",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import sklearn\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import os, sys, math\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda  \n",
    "\n",
    "from torchmetrics.classification import BinaryPrecision\n",
    "from torchmetrics.classification import BinaryRecall\n",
    "from torchmetrics.classification import BinaryF1Score\n",
    "from torchmetrics.classification import BinaryPrecisionRecallCurve\n",
    "from torchmetrics.classification import ROC\n",
    "from torchmetrics.classification import BinaryConfusionMatrix\n",
    "\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.nn.parallel import DataParallel\n",
    "from torch.cuda.amp import GradScaler, autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7952cc2-9469-4904-b3fa-4e85d021e98f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction of positives:  0.0208\n"
     ]
    }
   ],
   "source": [
    "# simulate labels\n",
    "np.random.seed(12345)\n",
    "N = 10000 \n",
    "d = 2500\n",
    "y = pd.Series(np.random.binomial(n = 1, p = 0.02, size = N))\n",
    "print(\"fraction of positives: \", sum(y)/len(y))\n",
    "X = np.random.normal(loc = 0, scale = 1, size = (N, d, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6789e37c-45ea-4089-b300-9cb55a4b164d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a198a145-d651-4e25-8979-fe7743ddc1ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def free_gpu_cache(verbose=True):\n",
    "    if verbose:\n",
    "        print(\"Initial GPU Usage\")\n",
    "        gpu_usage()                             \n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    #cuda.select_device(0)\n",
    "    #cuda.close()\n",
    "    #cuda.select_device(0)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"GPU Usage after emptying the cache\")\n",
    "        gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c5a4c48-4d09-4e64-891e-6ee26ad2a78a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncodingDataset(torch.utils.data.Dataset):\n",
    "  '''\n",
    "  Convert the list of PyTorch tensors into a PyTorch Dataset so I can use the DataLoader function for training\n",
    "  '''\n",
    "\n",
    "  def __init__(self, X, y):\n",
    "    #First, transpose each pd df since CONV1D takes as input vectors of shape [BxCxT] where B is minibatch size, C is # of channels, and T is sequence length    \n",
    "    X = [np.array(df.transpose()) for df in X]\n",
    "    #Then convert each dataframe into a PyTorch tensor\n",
    "    X = [torch.tensor(df) for df in X]\n",
    "    #Finally, cast the values in the tensors to float\n",
    "    X = [df.to(torch.float) for df in X]\n",
    "    self.X = X\n",
    "    \n",
    "    #convert each label into a PyTorch tensor\n",
    "    #Then I need to add an extra dimension so each label in y is a 1D PyTorch tensor instead of a 0D PyTorch tensor\n",
    "    y = [torch.tensor(np.array(label)) for label in y]\n",
    "    y = [label.to(torch.float) for label in y]\n",
    "    y = [torch.unsqueeze(label, dim=-1) for label in y]\n",
    "    self.y = y\n",
    "    \n",
    "  def __len__(self):\n",
    "      return len(self.X)\n",
    "\n",
    "  def __getitem__(self, i):\n",
    "      return self.X[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dd3d4d4-4d13-4e8a-8ce2-53ca4849c99a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class one_layer(nn.Module):\n",
    "    def __init__(self, kernel_size, in_channels, conv_size, l1, l2, dropout):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, conv_size, kernel_size, stride=1, padding=0)\n",
    "        self.conv1_batchnorm = nn.BatchNorm1d(conv_size)\n",
    "        self.conv1_dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.fc1 = nn.Linear(l1, l2)\n",
    "        self.fc2 = nn.Linear(l2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1_batchnorm(self.conv1(x))\n",
    "        out = F.max_pool1d(torch.relu(out), 2)\n",
    "        out = self.conv1_dropout(out)\n",
    "        \n",
    "        out = out.flatten(1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class two_layer(nn.Module):\n",
    "    def __init__(self, kernel_size, in_channels, conv_size, l2, dropout, dim):\n",
    "        super().__init__()\n",
    "        padding = 0\n",
    "        stride = 1\n",
    "        self.conv1 = nn.Conv1d(in_channels, conv_size, kernel_size, stride=stride, padding=padding)\n",
    "        self.conv1_batchnorm = nn.BatchNorm1d(conv_size)\n",
    "        out_dims = [conv_size, \n",
    "                    math.floor((dim + 2*padding - 1*(kernel_size - 1) - 1)/stride) + 1]\n",
    "        self.conv1_dropout = nn.Dropout(p=dropout)\n",
    "        out_dims = [conv_size, \n",
    "                    math.floor((out_dims[1] + 2*padding - 1*(2 - 1) - 1)/2) + 1]\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(conv_size, conv_size, kernel_size, stride=1, padding=padding)\n",
    "        out_dims = [conv_size, \n",
    "                    math.floor((out_dims[1] + 2*padding - 1*(kernel_size - 1) - 1)/stride) + 1]\n",
    "        self.conv2_batchnorm = nn.BatchNorm1d(conv_size)\n",
    "        out_dims = [conv_size, \n",
    "                    math.floor((out_dims[1] + 2*padding - 1*(2 - 1) - 1)/2) + 1]\n",
    "        self.conv2_dropout = nn.Dropout(p=dropout)\n",
    "        l1 = out_dims[0]*out_dims[1]\n",
    "        self.fc1 = nn.Linear(l1, l2)\n",
    "        self.fc2 = nn.Linear(l2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1_batchnorm(self.conv1(x))\n",
    "        out = F.max_pool1d(torch.relu(out), 2)\n",
    "        out = self.conv1_dropout(out)\n",
    "        \n",
    "        out = self.conv2_batchnorm(self.conv2(out))\n",
    "        out = F.max_pool1d(torch.relu(out), 2)\n",
    "        out = self.conv2_dropout(out)\n",
    "        \n",
    "        out = out.flatten(1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class three_layer(nn.Module):\n",
    "    def __init__(self, kernel_size, in_channels, conv_size, l2, dropout, dim):\n",
    "        super().__init__()\n",
    "        padding = 0\n",
    "        stride = 1\n",
    "        self.conv1 = nn.Conv1d(in_channels, conv_size, kernel_size, stride=stride, padding=padding)\n",
    "        out_dims = [conv_size, \n",
    "                    math.floor((dim + 2*padding - 1*(kernel_size - 1) - 1)/stride) + 1]\n",
    "        self.conv1_batchnorm = nn.BatchNorm1d(conv_size)\n",
    "        out_dims = [conv_size, \n",
    "                    math.floor((out_dims[1] + 2*padding - 1*(2 - 1) - 1)/2) + 1]\n",
    "        self.conv1_dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(conv_size, conv_size, kernel_size, stride=stride, padding=padding)\n",
    "        out_dims = [conv_size, \n",
    "                    math.floor((out_dims[1] + 2*padding - 1*(kernel_size - 1) - 1)/stride) + 1]\n",
    "        self.conv2_batchnorm = nn.BatchNorm1d(conv_size)\n",
    "        out_dims = [conv_size, \n",
    "                    math.floor((out_dims[1] + 2*padding - 1*(2 - 1) - 1)/2) + 1]\n",
    "        self.conv2_dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(conv_size, conv_size, kernel_size, stride=stride, padding=padding)\n",
    "        out_dims = [conv_size, \n",
    "                    math.floor((out_dims[1] + 2*padding - 1*(kernel_size - 1) - 1)/stride) + 1]\n",
    "        self.conv3_batchnorm = nn.BatchNorm1d(conv_size)\n",
    "        out_dims = [conv_size, \n",
    "                    math.floor((out_dims[1] + 2*padding - 1*(2 - 1) - 1)/2) + 1]\n",
    "        self.conv3_dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        l1 = out_dims[0]*out_dims[1]\n",
    "        self.fc1 = nn.Linear(l1, l2)\n",
    "        self.fc2 = nn.Linear(l2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1_batchnorm(self.conv1(x))\n",
    "        #print(\"first convolution:\", out.shape)\n",
    "        out = F.max_pool1d(torch.relu(out), 2)\n",
    "        #print(\"first max pool: \", out.shape)\n",
    "        out = self.conv1_dropout(out)\n",
    "        #print(\"first dropout: \", out.shape)\n",
    "        \n",
    "        out = self.conv2_batchnorm(self.conv2(out))\n",
    "        #print(\"2nd conv: \", out.shape)\n",
    "        out = F.max_pool1d(torch.relu(out), 2)\n",
    "        #print(\"2nd max pool: \", out.shape)\n",
    "        out = self.conv2_dropout(out)\n",
    "        #print(\"2nd dropout: \", out.shape)\n",
    "        out = self.conv3_batchnorm(self.conv3(out))\n",
    "        #print(\"3rd conv: \", out.shape)\n",
    "        out = F.max_pool1d(torch.relu(out), 2)\n",
    "        #print(\"3rd max pool: \", out.shape)\n",
    "        out = self.conv3_dropout(out)\n",
    "        #print(out.shape)\n",
    "        \n",
    "        out = out.flatten(1)\n",
    "        #print(\"flattened: \", out.shape)\n",
    "        out = self.fc1(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38be5d42-a0ad-4a68-a7ae-48964eebd91d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(n_epochs, optimizer, model, loss_fn, train_loader_batch):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for encodings, labels in train_loader_batch:\n",
    "            encodings = encodings.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            \n",
    "            outputs = model(encodings)\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "            \n",
    "def evaluate_model(model, train_loader_eval, test_loader_eval):\n",
    "    \n",
    "    train_probs_list, train_preds_list, train_labels_list = [], [], []\n",
    "    for encodings, labels in train_loader_eval:\n",
    "        with torch.no_grad():\n",
    "            train_encodings = encodings.to(device=device)\n",
    "            train_labels = labels.to(device=device)\n",
    "\n",
    "            #Get model predictions on test set data\n",
    "            train_outputs = model(train_encodings)\n",
    "            train_probs = torch.sigmoid(train_outputs)        \n",
    "            train_preds = torch.round(train_probs)\n",
    "\n",
    "            #Convert to correct format\n",
    "            train_labels = train_labels.type(torch.int64)\n",
    "            train_preds = train_preds.type(torch.int64) \n",
    "        for i in range(0,len(encodings)):\n",
    "            train_probs_list.append(train_probs[i])\n",
    "            train_preds_list.append(train_preds[i])\n",
    "            train_labels_list.append(train_labels[i])\n",
    "    \n",
    "    val_probs_list, val_preds_list, val_labels_list = [], [], []\n",
    "    for encodings, labels in test_loader_eval:\n",
    "        with torch.no_grad():\n",
    "            val_encodings = encodings.to(device=device)\n",
    "            val_labels = labels.to(device=device)\n",
    "\n",
    "            #Get model predictions on test set data\n",
    "            val_outputs = model(val_encodings)\n",
    "            val_probs = torch.sigmoid(val_outputs)        \n",
    "            val_preds = torch.round(val_probs)\n",
    "\n",
    "            #Convert to correct format\n",
    "            val_labels = val_labels.type(torch.int64)\n",
    "            val_preds = val_preds.type(torch.int64)\n",
    "        for i in range(0,len(encodings)):\n",
    "            val_probs_list.append(val_probs[i])\n",
    "            val_preds_list.append(val_preds[i])\n",
    "            val_labels_list.append(val_labels[i])\n",
    "    \n",
    "    model_performance = {\"train_probs\":torch.stack(train_probs_list),\n",
    "                         \"train_preds\":torch.stack(train_preds_list),\n",
    "                         \"train_labels\":torch.stack(train_labels_list),\n",
    "                         \"val_probs\":torch.stack(val_probs_list),\n",
    "                         \"val_preds\":torch.stack(val_preds_list),\n",
    "                         \"val_labels\":torch.stack(val_labels_list),\n",
    "                        }\n",
    "    \n",
    "    return(model_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9d5138c-ee3f-46bd-93ae-4fa692525bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_minority_class(X, y, upsampling_fraction):\n",
    "    \"\"\"\n",
    "    Inputs: list of encodings X, binary feature labels y, upsampling fraction [0,1]\n",
    "    Upsamples the minority class (1) of the input dataframe and outputs a list of encodings containing a more balanced dataset\n",
    "    (i.e. if upsampling_fraction=0.3, then 30% of the resulting list will be sampled from the minority class)\n",
    "    \"\"\"\n",
    "    \n",
    "    if upsampling_fraction == 0:\n",
    "        return(X, y)\n",
    "    \n",
    "    else:\n",
    "        maj_index = [i for i in range(len(y)) if y[i]==1]\n",
    "        minority_index = [i for i in range(len(y)) if y[i]==0]\n",
    "        maj_list = [X[i] for i in maj_index]\n",
    "        minority_list = [X[i] for i in minority_index]\n",
    "        \n",
    "        n_samples = round((upsampling_fraction*len(X) - len(maj_list))/(1-upsampling_fraction))\n",
    "        upsampled_encodings_minority = [random.choice(minority_list) for _ in range(n_samples)]\n",
    "        upsampled_encodings_minority.extend(minority_list)\n",
    "        \n",
    "        upsampled_encodings_full = upsampled_encodings_minority\n",
    "        upsampled_encodings_full.extend(maj_list)\n",
    "        \n",
    "        upsampled_labels_full = ([1] * (n_samples + len(minority_list)))\n",
    "        upsampled_labels_full.extend([0] * len(maj_list))\n",
    "        \n",
    "        return(upsampled_encodings_full, upsampled_labels_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c54308c-7a12-4ff6-b150-ac525ebe47bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def CNN_hyperparameter_tuning_CV(param_grid):\n",
    "    \"\"\"\n",
    "    Inputs: hyperparameter grid and fraction to upsample the data\n",
    "    \n",
    "    This function trains and evaluates CNN models for a particular encoding featurespace and returns \n",
    "    training/validation scoring metrics using K-fold cross-validation\n",
    "    \"\"\"\n",
    "    score_tracker = []\n",
    "    for model_name in param_grid['model_name']:\n",
    "        for weight_decay in param_grid['weight_decay']:\n",
    "            for learning_rate in param_grid['learning_rate']:\n",
    "                for batch_size in param_grid['batch_size']:\n",
    "                    for dropout in param_grid['dropout']:\n",
    "                        for conv_size in param_grid['conv_size']:\n",
    "                            for n_epochs in param_grid['n_epochs']:\n",
    "                                for layer2 in param_grid['layer2']:\n",
    "                                    for upsample_frac in param_grid['upsample_frac']:\n",
    "                                        for kernel_size in param_grid['kernel_size']:\n",
    "                                                \n",
    "                                                free_gpu_cache(verbose=False)\n",
    "                                \n",
    "                                                #device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "                                                #      else torch.device('cpu'))\n",
    "                                                #print(f\"Training on device {device}.\")\n",
    "                                                start = time.time()\n",
    "    \n",
    "                                                metrics = {\"n_epochs\": n_epochs,\n",
    "                                                           \"weight_decay\": weight_decay,\n",
    "                                                           \"learning_rate\": learning_rate,\n",
    "                                                           \"batch_size\": batch_size,\n",
    "                                                           \"dropout\": dropout,\n",
    "                                                           \"conv_size\": conv_size,\n",
    "                                                           \"model_name\": model_name,\n",
    "                                                           \"layer2\": layer2,\n",
    "                                                           \"upsample_frac\": upsample_frac,\n",
    "                                                           \"kernel_size\": kernel_size} \n",
    "                                                #print(\"metrics: \", metrics)\n",
    "            \n",
    "\n",
    "                                                train_recall_scores = []\n",
    "                                                train_precision_scores = []\n",
    "                                                train_f1_scores = []\n",
    "                                                train_pr_auc_scores = []\n",
    "                                                train_roc_auc_scores = []\n",
    "                                                train_conf_matrices = []\n",
    "\n",
    "                                                val_recall_scores = []\n",
    "                                                val_precision_scores = []\n",
    "                                                val_f1_scores = []\n",
    "                                                val_pr_auc_scores = []\n",
    "                                                val_roc_auc_scores = []\n",
    "                                                val_conf_matrices = []\n",
    "\n",
    "                                                cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "                                                for train_fold_index, val_fold_index in cv.split(X, Y):\n",
    "                                                    # Get the training data\n",
    "                                                    X_train_fold = [X[i] for i in train_fold_index]\n",
    "                                                    Y_train_fold = [Y[i] for i in train_fold_index]\n",
    "                                    \n",
    "                                                    # Get the validation data\n",
    "                                                    X_val_fold = [X[i] for i in val_fold_index]\n",
    "                                                    Y_val_fold = [Y[i] for i in val_fold_index]\n",
    "\n",
    "                                                    # Upsample only the data in the training section\n",
    "                                                    X_train_fold_upsample, Y_train_fold_upsample = upsample_minority_class(X_train_fold, Y_train_fold, upsampling_fraction=0.3)\n",
    "                                                    del X_train_fold\n",
    "                                                    del Y_train_fold\n",
    "\n",
    "                                                    train_data = EncodingDataset(X_train_fold_upsample,Y_train_fold_upsample)\n",
    "                                                    val_data = EncodingDataset(X_val_fold,Y_val_fold)\n",
    "\n",
    "                                                    train_loader_batch = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "                                                    test_loader_batch = torch.utils.data.DataLoader(val_data, batch_size=batch_size, num_workers=8)\n",
    "                                    \n",
    "                                                    if model_name == \"1layer\":\n",
    "                                                        model = one_layer(kernel_size = 10, \n",
    "                                                                      in_channels = X_train_fold_upsample[0].shape[1], \n",
    "                                                                      conv_size = conv_size, \n",
    "                                                                      in_size = X_train_fold_upsample[0].shape[0], \n",
    "                                                                      l2 = l2, \n",
    "                                                                      dropout = dropout)\n",
    "                                                    if model_name == \"2layer\":\n",
    "                                                        model = two_layer(kernel_size = kernel_size, \n",
    "                                                                            in_channels = X_train_fold_upsample[0].shape[1], \n",
    "                                                                            conv_size = conv_size, \n",
    "                                                                            l2 = layer2, \n",
    "                                                                            dropout = dropout,\n",
    "                                                                            dim = X_train_fold_upsample[0].shape[0])\n",
    "                                                    if model_name == \"3layer\":\n",
    "                                                        model = three_layer(kernel_size = kernel_size, \n",
    "                                                                            in_channels = X_train_fold_upsample[0].shape[1], \n",
    "                                                                            conv_size = conv_size, \n",
    "                                                                            l2 = layer2, \n",
    "                                                                            dropout = dropout,\n",
    "                                                                            dim = X_train_fold_upsample[0].shape[0])\n",
    "\n",
    "                                                    #model = nn.parallel.DataParallel(model)\n",
    "                                                    model.to(device)\n",
    "                                    \n",
    "                                                    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "                                                    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "                                                    # Fit the model on the upsampled training data\n",
    "                                                    train_model(\n",
    "                                                        n_epochs = n_epochs,\n",
    "                                                        optimizer = optimizer,\n",
    "                                                        model = model,\n",
    "                                                        loss_fn = loss_fn,\n",
    "                                                        train_loader_batch = train_loader_batch\n",
    "                                                    )\n",
    "                                    \n",
    "                                                    model_performance = evaluate_model(model, train_loader_batch, test_loader_batch)\n",
    "\n",
    "\n",
    "                                                    # Score the model on the upsampled training data and non-upsampled validation data: PRECISION\n",
    "                                                    precision = BinaryPrecision(threshold=0.5).to(device)\n",
    "                                                    train_precision_scores.append(precision(model_performance[\"train_preds\"], model_performance[\"train_labels\"]).cpu().numpy())\n",
    "                                                    val_precision_scores.append(precision(model_performance[\"val_preds\"], model_performance[\"val_labels\"]).cpu().numpy())\n",
    "\n",
    "                                                    # Score the model on the upsampled training data and non-upsampled validation data: RECALL\n",
    "                                                    recall = BinaryRecall(threshold=0.5).to(device)\n",
    "                                                    train_recall_scores.append(recall(model_performance[\"train_preds\"], \n",
    "                                                                              model_performance[\"train_labels\"]).cpu().numpy())\n",
    "                                                    val_recall_scores.append(recall(model_performance[\"val_preds\"], \n",
    "                                                                            model_performance[\"val_labels\"]).cpu().numpy())\n",
    "\n",
    "                                                    # Score the model on the upsampled training data and non-upsampled validation data: F1 SCORE\n",
    "                                                    f1_score = BinaryF1Score().to(device)\n",
    "                                                    train_f1_scores.append(f1_score(model_performance[\"train_preds\"], \n",
    "                                                                            model_performance[\"train_labels\"]).cpu().numpy())\n",
    "                                                    val_f1_scores.append(f1_score(model_performance[\"val_preds\"], \n",
    "                                                                          model_performance[\"val_labels\"]).cpu().numpy())\n",
    "\n",
    "                                                    # Score the model on the upsampled training data and non-upsampled validation data: PR AUC\n",
    "                                                    pr_curve = BinaryPrecisionRecallCurve(thresholds=None).to(device)\n",
    "                                                    precision_PR, recall_PR, thresholds_PR = pr_curve(model_performance[\"train_probs\"], \n",
    "                                                                                              model_performance[\"train_labels\"])\n",
    "                                                    train_pr_auc_scores.append(sklearn.metrics.auc(recall_PR.cpu().numpy(), \n",
    "                                                                                           precision_PR.cpu().numpy()))\n",
    "                                                    precision_PR, recall_PR, thresholds_PR = pr_curve(model_performance[\"val_probs\"], \n",
    "                                                                                              model_performance[\"val_labels\"])\n",
    "                                                    val_pr_auc_scores.append(sklearn.metrics.auc(recall_PR.cpu().numpy(), precision_PR.cpu().numpy()))\n",
    "                                                    \n",
    "                                                    roc_curve = ROC(task=\"binary\", thresholds=None).to(device)\n",
    "                                                    train_fpr, train_tpr, train_thresholds = roc_curve(model_performance[\"train_probs\"], \n",
    "                                                                                    model_performance[\"train_labels\"])\n",
    "                                                    train_roc_auc_scores.append(sklearn.metrics.auc(train_fpr.cpu().numpy(), \n",
    "                                                                                           train_tpr.cpu().numpy()))\n",
    "                                                    val_fpr, val_tpr, val_thresholds = roc_curve(model_performance[\"train_probs\"], \n",
    "                                                                                    model_performance[\"train_labels\"])\n",
    "                                                    val_roc_auc_scores.append(sklearn.metrics.auc(val_fpr.cpu().numpy(), \n",
    "                                                                                           val_tpr.cpu().numpy()))\n",
    "                                                    \n",
    "\n",
    "                                                    #Get confusion matrices\n",
    "                                                    confmat_test = BinaryConfusionMatrix().to(device)\n",
    "                                                    train_conf_matrices.append(confmat_test(model_performance[\"train_preds\"], model_performance[\"train_labels\"]).cpu().numpy())\n",
    "                                                    val_conf_matrices.append(confmat_test(model_performance[\"val_preds\"], \n",
    "                                                                                  model_performance[\"val_labels\"]).cpu().numpy())\n",
    "                                                # end CV loop\n",
    "\n",
    "                                                stop = time.time()\n",
    "\n",
    "                                                metrics['train_precision_score'] = np.mean(train_precision_scores)\n",
    "                                                metrics['train_recall_score'] = np.mean(train_recall_scores)\n",
    "                                                metrics['train_f1_score'] = np.mean(train_f1_scores)\n",
    "                                                metrics['train_pr_auc_score'] = np.mean(train_pr_auc_scores)\n",
    "                                                metrics['train_roc_auc_score'] = np.mean(train_roc_auc_scores)\n",
    "                                                metrics['train_conf_matrix'] = np.mean(train_conf_matrices, axis=0)\n",
    "                                                metrics['val_precision_score'] = np.mean(val_precision_scores)\n",
    "                                                metrics['val_recall_score'] = np.mean(val_recall_scores)\n",
    "                                                metrics['val_f1_score'] = np.mean(val_f1_scores)\n",
    "                                                metrics['val_pr_auc_score'] = np.mean(val_pr_auc_scores)\n",
    "                                                metrics['val_roc_auc_score'] = np.mean(val_roc_auc_scores)\n",
    "                                                metrics['val_conf_matrix'] = np.mean(val_conf_matrices, axis=0)\n",
    "                                                metrics[\"time\"] = stop-start\n",
    "\n",
    "                                                score_tracker.append(metrics)\n",
    "\n",
    "                                                score_tracker_csv = pd.DataFrame(score_tracker)\n",
    "\n",
    "                                                score_tracker_csv.to_csv('out/CNN/_params_running_v2.csv')\n",
    "    return score_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b42dc08d-fb8e-4474-9721-2c61d2a99af3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#NOTE: EVALUATING WITH 5-FOLD CV\n",
    "param_grid = {\"model_name\": [\"2layer\", \"3layer\"],\n",
    "              \"weight_decay\": [0.01,0.05],\n",
    "              \"learning_rate\": [1e-3,1e-6],\n",
    "              \"batch_size\": [2, 8],\n",
    "              \"dropout\": [0,0.2],\n",
    "              \"conv_size\": [5,50],\n",
    "              \"n_epochs\": [10,30],\n",
    "              \"layer2\": [10,20],\n",
    "              \"upsample_frac\": [0,0.3],\n",
    "              \"kernel_size\": [5,10]\n",
    "             }\n",
    "# total number: 2^10 = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac74690-8a6b-4d06-9b0d-e027b851e6f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")\n",
    "\n",
    "#Subselecting peptide sequences to remove those with low coverage from screen\n",
    "X = [X[i] for i in range(X.shape[0])]\n",
    "Y = list(y)\n",
    "\n",
    "#SUBSAMPLING FOR DEBUGGING\n",
    "#X = X[0:100]\n",
    "#Y = Y[0:100]\n",
    "\n",
    "#RUN CNN W/ HYPERPARAMETER TUNING ON THIS ENCODING\n",
    "torch.backends.cudnn.benchmark = True\n",
    "score_tracker = CNN_hyperparameter_tuning_CV(param_grid)\n",
    "score_tracker_csv = pd.DataFrame(score_tracker)\n",
    "score_tracker_csv.to_csv('Out/CNN/' + encoding_method + '_params_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945cf8e7-a88c-4443-b8fb-5e7385ba8929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
