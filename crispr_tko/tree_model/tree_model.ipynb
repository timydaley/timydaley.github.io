{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "legitimate-slide",
   "metadata": {},
   "source": [
    "There is an endemic problem today in Bioinformatics.  With Deep Learning$^{\\text{TM}}$ becoming the next Hot New Thing, the Bioinformatics community has worked quickly to catch up.  However, I think some important lessons of the Machine Learning community have not filtered through to the Bioinformatics community.  Specifically the big issue in how to choose a test set.\n",
    "\n",
    "# What purpose does a test set serve?\n",
    "\n",
    "The fundamental purpose of a test set is a fair and honest evaluation of the performance of the trained model.  In other words, the test set is used to answer the question: if we train the model and use int on future data, how well can we expect the model to perform.  The honesty part is absolutely critical, because otherwise we're going to overpromise the performance.  This is why the machine learning community hammers on the concept of a proper test set.  And it also guides the choice of the test set. I'll illustrate this with some examples.\n",
    "\n",
    "## Examples\n",
    "\n",
    "Suppose we want to build a model to predict stock prices.  If we train the model today, then we would be able to predict prices for tomorrow.  In particular, no information from tomorrow will be seen by the model during training.   In particular, if stocks A & B are correlated, say they're both in the same industry and will be similarly affected by underlying economic conditions, then we cannot use the fact that if stock A is up then so will stock B (except in a Granger sense, meaning we can use the current rise in A to predict a likely rise of B in the future).  Or if there is some economic event that causes a general shift in stock prices.  The latter would be apparent if you saw 80% of future prices, but not if you saw none of them.  Therefore the proper split to simulate this behavior is to take a time-based split.  If we don't do this, then we would fool ourselves in the performance of the algorithm and it's possible that we might deploy an algorithm that under-performs and loses us money.\n",
    "\n",
    "Or consider the following example from [r/MachineLearning](https://www.reddit.com/r/MachineLearning/comments/c4ylga/d_misuse_of_deep_learning_in_nature_journals/): a Nature paper proposed a deep neural network to predict the location of aftershocks.  If we train a model today and an earthquake happens tomorrow, then what information is available to predict the location of the subsequent aftershocks?  We can use past earthquakes and aftershocks, as well as information we get from the initial earthquake.  What we don't get is aftershocks from the current earthquake.  Therefore, a proper split would be either by time (as above) or by earthquakes grouped with their aftershocks.  As the post above shows, doing the latter type of split results in a simple regularized regression having better test set performance, which indicates that the deep neural network is over-fitting.  \n",
    "\n",
    "Now consider examples from bioinformatics.  Suppose we want to build a model to predict which guide RNAs are going to be effective.  If we want to apply the model to help design guides in a new experiment, then we would very typically not have access to a previous experiment in the same cell type and target phenotype (that we are trying to select for).  If we did, then we can just use that experiment to select which guides to use.  In particular, if we use the same experiment to predict and evaluate the model then there will be several confounders such as batch effects which will make us over-confident in  our predictions.  [One paper](https://www.nature.com/articles/nbt.4061) clearly showed this with an out-of-sample test set (hidden in the supplementary) where simple regularized regression showed better performance than their proposed deep learning model.  \n",
    "\n",
    "Now consider the problem of predicting gene expression from other modalities, such as the promoter genetic sequence plus open chromatin of the particular cell type.  If we want to deploy the model, then we would take the model, the genetic sequence, and open chromatin data to predict the gene expression of a sample for which we have no gene expression data on, like a new patient sample.  The key here is that there a lot of biological (cell type to cell type or person to person) variation and batch effects present.  These effects hugely impact the variation, but they won't be available to the model in production.  Therefore, if the model is able \"see\" those batch effects (say using a simple train-test split), we will overestimate the accuracy of the model.  \n",
    "\n",
    "\n",
    "# Example: guide RNA design\n",
    "\n",
    "To clearly illustrate how this issue arises we'll use the third example above.  Let's say we want to build a model to improve on-target effects for CRISPRko (CRISPR knockout) guides.  To train the model we'll use the [Toronto Knockout Library](http://tko.ccbr.utoronto.ca/) dataset, a collection of CRISPRko experiments on 5 different cell lines for gene essentiallity.  To remove the bias of biological effect and the bias of using the training data to select positive hit genes, we'll subset the training data to previously known essential genes (from http://www.ncbi.nlm.nih.gov/pubmed/24987113).  \n",
    "\n",
    "First what we'll have to do is process the counts to convert it to log fold change.  We'll do this using all guides.\n",
    "\n",
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cardiovascular-cursor",
   "metadata": {},
   "source": [
    "# this was done in R outside and is not run in this notebook\n",
    "tko_loc = '/Users/tim.daley/blog/timydaley.github.io/crispr_tko/'\n",
    "libs = c(\"DLD1\", \"GBM\", \"HCT116_1\", \"HeLa\", \"RPE1\")\n",
    "df_list = list()\n",
    "for(l in libs){\n",
    "  loc = paste0(tko_loc, \"readcount-\", l, \"-lib1\")\n",
    "  x = read.table(loc, header = T)\n",
    "  df_list[[l]] = x\n",
    "}\n",
    "for(l in libs){\n",
    "  df_list[[l]][\"SEQ\"] = sapply(df_list[[l]]$GENE_CLONE, function(s) unlist(strsplit(s, \"_\"))[2])\n",
    "}\n",
    "design_matrices = list()\n",
    "counts_list = list()\n",
    "# we need custom design matrices for each experiment because the designs are not identical\n",
    "# DLD1\n",
    "counts_list[[\"DLD1\"]] = df_list[[\"DLD1\"]][c(\"DLD_T0\", \"DLD_ETOH_R1\", \"DLD_ETOH_R2\", \"DLD_ETOH_R3\")]\n",
    "design_matrices[[\"DLD1\"]] = data.frame(condition = c(0, 1, 1, 1), row.names = colnames(counts_list[[\"DLD1\"]]))\n",
    "# GBM\n",
    "counts_list[[\"GBM\"]] = df_list[[\"GBM\"]][c(\"T0\", \"T21A\", \"T21B\")]\n",
    "design_matrices[[\"GBM\"]] = data.frame(condition = c(0, 1, 1), row.names = colnames(counts_list[[\"GBM\"]]))\n",
    "# HCT116_1\n",
    "counts_list[[\"HCT116_1\"]] = df_list[[\"HCT116_1\"]][c(\"LIB1_T0\", \"LIB1_T18_A\", \"LIB1_T18_B\")]\n",
    "design_matrices[[\"HCT116_1\"]] = data.frame(condition = c(0, 1, 1), row.names = colnames(counts_list[[\"HCT116_1\"]]))\n",
    "# HeLa\n",
    "counts_list[[\"HeLa\"]] = df_list[[\"HeLa\"]][c(\"T0\", \"T18A\", \"T18B\", \"T18C\")]\n",
    "design_matrices[[\"HeLa\"]] = data.frame(condition = c(0, 1, 1, 1), row.names = colnames(counts_list[[\"HeLa\"]]))\n",
    "# RPE1\n",
    "counts_list[[\"RPE1\"]] = df_list[[\"RPE1\"]][c(\"T0\", \"T18A\", \"T18B\")]\n",
    "design_matrices[[\"RPE1\"]] = data.frame(condition = c(0, 1, 1), row.names = colnames(counts_list[[\"RPE1\"]]))\n",
    "# now compute log2 fold changes\n",
    "log2fc_list = list()\n",
    "for(l in libs){\n",
    "  d = DESeq2::DESeqDataSetFromMatrix(countData = counts_list[[l]],\n",
    "                                     colData = design_matrices[[l]],\n",
    "                                     design = ~condition)\n",
    "  d = DESeq2::DESeq(d)\n",
    "  d = DESeq2::results(d)\n",
    "  log2fc_list[[l]] = data.frame(d, seq = df_list[[l]]$SEQ, gene = df_list[[l]]$GENE)\n",
    "}\n",
    "# now subset to known positive genes\n",
    "#essential_genes = factor(scan(paste0(tko_loc, \"ConstitutiveCoreEssentialGenes.txt\"), what = character()))\n",
    "essential_genes = read.table(file = paste0(tko_loc, \"reference_essentials_and_nonessentials_sym_hgnc_entrez/constitutive_core_essentials_hg-Table1.tsv\"), header = T)\n",
    "#sum(essential_genes$Gene %in% factor(df_list[[\"DLD1\"]]$GENE))\n",
    "\n",
    "# what we really want is a table with log2fc, guide sequence, gene, and cell type\n",
    "log2fc = data.frame()\n",
    "for(l in libs){\n",
    "  log2fc = rbind(log2fc, data.frame(log2fc_list[[l]][c(\"seq\", \"gene\", \"log2FoldChange\")], lib = l))\n",
    "}\n",
    "log2fc['essential'] = 1*(log2fc$gene %in% essential_genes$Gene)\n",
    "write.table(log2fc, file = paste0(tko_loc, \"CombinedLog2FoldChanges.txt\"), quote = F, sep = '\\t', row.names = F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "impressive-diameter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T00:23:23.713097Z",
     "start_time": "2021-09-28T00:23:22.834406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(456600, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>gene</th>\n",
       "      <th>log2FoldChange</th>\n",
       "      <th>lib</th>\n",
       "      <th>essential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CACCTTCGAGCTGCTGCGCG</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>-0.198332</td>\n",
       "      <td>DLD1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAGAGCGCCTCGGTCCCAGC</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>-0.631673</td>\n",
       "      <td>DLD1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TGGACTTCCAGCTACGGCGC</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>-1.315708</td>\n",
       "      <td>DLD1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CACTGGCGCCATCGAGAGCC</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>0.989644</td>\n",
       "      <td>DLD1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GCTCGGGCTTGTCCACAGGA</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>0.021679</td>\n",
       "      <td>DLD1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    seq  gene  log2FoldChange   lib  essential\n",
       "0  CACCTTCGAGCTGCTGCGCG  A1BG       -0.198332  DLD1          0\n",
       "1  AAGAGCGCCTCGGTCCCAGC  A1BG       -0.631673  DLD1          0\n",
       "2  TGGACTTCCAGCTACGGCGC  A1BG       -1.315708  DLD1          0\n",
       "3  CACTGGCGCCATCGAGAGCC  A1BG        0.989644  DLD1          0\n",
       "4  GCTCGGGCTTGTCCACAGGA  A1BG        0.021679  DLD1          0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "log2fc_df = pd.read_csv(\"../CombinedLog2FoldChanges.txt\", sep = '\\t')\n",
    "print(log2fc_df.shape)\n",
    "log2fc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stupid-telling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T00:23:23.779007Z",
     "start_time": "2021-09-28T00:23:23.716092Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chr10         6900\n",
       "LacZ           480\n",
       "luciferase     120\n",
       "EGFP           110\n",
       "MBNL1           30\n",
       "              ... \n",
       "LIN28A           5\n",
       "HNRNPL           5\n",
       "ASB17            5\n",
       "LILRA3           5\n",
       "THOC7            5\n",
       "Name: gene, Length: 17236, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log2fc_df['gene'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "powered-peace",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T00:23:23.840341Z",
     "start_time": "2021-09-28T00:23:23.782187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30      12037\n",
       "25       1642\n",
       "20       1087\n",
       "15        887\n",
       "5         801\n",
       "10        778\n",
       "480         1\n",
       "6900        1\n",
       "120         1\n",
       "110         1\n",
       "Name: gene, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log2fc_df['gene'].value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-paintball",
   "metadata": {},
   "source": [
    "Note that `chr10`, `LacZ`, and `luciferase` are control guides.  Well, that's what they were designed for, but in fact some of these guides have a non-null effect.    For most of the genes there are 30 guides per gene.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "equivalent-disclaimer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T00:23:23.849851Z",
     "start_time": "2021-09-28T00:23:23.842629Z"
    }
   },
   "outputs": [],
   "source": [
    "log2fc_df.loc[log2fc_df['log2FoldChange'].isna(), 'log2FoldChange'] = 0\n",
    "# subset to essential genes and negative controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sophisticated-adams",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T00:23:23.895926Z",
     "start_time": "2021-09-28T00:23:23.852112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RPE1        91320\n",
       "DLD1        91320\n",
       "HeLa        91320\n",
       "HCT116_1    91320\n",
       "GBM         91320\n",
       "Name: lib, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# breakdown between libraries\n",
    "log2fc_df['lib'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "missing-defensive",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T00:26:48.744629Z",
     "start_time": "2021-09-28T00:23:23.898149Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def seq_to_one_hot(seq):\n",
    "    # transform sequence into an array\n",
    "    seq_array = np.array(list(seq))\n",
    "    \n",
    "    #integer encode the sequence\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded_seq = label_encoder.fit_transform(seq_array)\n",
    "    #one hot the sequence\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    #reshape because that's what OneHotEncoder likes\n",
    "    integer_encoded_seq = integer_encoded_seq.reshape(len(integer_encoded_seq), 1)\n",
    "    onehot_encoded_seq = onehot_encoder.fit_transform(integer_encoded_seq)\n",
    "    return onehot_encoded_seq.flatten()\n",
    "\n",
    "log2fc_df['sklearn_1hot'] = log2fc_df['seq'].map(lambda s: seq_to_one_hot(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "loving-malta",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T00:26:48.766170Z",
     "start_time": "2021-09-28T00:26:48.746629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>gene</th>\n",
       "      <th>log2FoldChange</th>\n",
       "      <th>lib</th>\n",
       "      <th>essential</th>\n",
       "      <th>sklearn_1hot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CACCTTCGAGCTGCTGCGCG</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>-0.198332</td>\n",
       "      <td>DLD1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAGAGCGCCTCGGTCCCAGC</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>-0.631673</td>\n",
       "      <td>DLD1</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TGGACTTCCAGCTACGGCGC</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>-1.315708</td>\n",
       "      <td>DLD1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CACTGGCGCCATCGAGAGCC</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>0.989644</td>\n",
       "      <td>DLD1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GCTCGGGCTTGTCCACAGGA</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>0.021679</td>\n",
       "      <td>DLD1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    seq  gene  log2FoldChange   lib  essential  \\\n",
       "0  CACCTTCGAGCTGCTGCGCG  A1BG       -0.198332  DLD1          0   \n",
       "1  AAGAGCGCCTCGGTCCCAGC  A1BG       -0.631673  DLD1          0   \n",
       "2  TGGACTTCCAGCTACGGCGC  A1BG       -1.315708  DLD1          0   \n",
       "3  CACTGGCGCCATCGAGAGCC  A1BG        0.989644  DLD1          0   \n",
       "4  GCTCGGGCTTGTCCACAGGA  A1BG        0.021679  DLD1          0   \n",
       "\n",
       "                                        sklearn_1hot  \n",
       "0  [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log2fc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "connected-center",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T00:26:48.968426Z",
     "start_time": "2021-09-28T00:26:48.770628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80    448985\n",
       "60      7575\n",
       "40        40\n",
       "Name: sklearn_1hot, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log2fc_df['sklearn_1hot'].map(lambda s: len(s)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "familiar-transparency",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T00:26:49.134477Z",
     "start_time": "2021-09-28T00:26:48.971757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20    456600\n",
       "Name: seq, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log2fc_df['seq'].map(lambda s: len(s)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "republican-forest",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T00:26:49.213943Z",
     "start_time": "2021-09-28T00:26:49.136134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DLD1        2888\n",
       "GBM         2888\n",
       "HeLa        2888\n",
       "HCT116_1    2888\n",
       "RPE1        2888\n",
       "Name: lib, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essential_data = log2fc_df[(log2fc_df['essential'] == 1) | (log2fc_df['gene'] == 'chr10')].copy()\n",
    "#essential_data.loc[essential_data['log2FoldChange'].isna(), 'log2FoldChange'] = 0\n",
    "essential_data = essential_data.reset_index(drop = True)\n",
    "essential_data['lib'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-bolivia",
   "metadata": {},
   "source": [
    "So the problem is not variable sequence length, rather the LabelEncoder has difficulty with unseen data.  The solution on stackoverflow is to switch to pandas (https://stackoverflow.com/a/33761341)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "amateur-academy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T00:26:49.312695Z",
     "start_time": "2021-09-28T00:26:49.216292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0  1  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17 18 19\n",
       "0  G  G  A  T  C  C  T  A  T  A  C  T  G  T  G  A  G  A  G  C\n",
       "1  G  G  C  G  A  T  A  A  A  G  G  C  A  A  A  C  A  A  G  G\n",
       "2  T  A  A  T  G  C  T  C  T  G  C  G  T  G  T  T  C  C  G  A\n",
       "3  A  G  G  A  C  A  T  A  G  C  C  A  T  C  G  T  G  G  A  C\n",
       "4  G  A  T  G  G  C  T  A  T  G  T  C  C  T  T  C  A  A  C  A"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_array = pd.DataFrame(np.array([list(x) for x in essential_data['seq']]))\n",
    "seq_array.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "premium-center",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T00:26:49.373933Z",
     "start_time": "2021-09-28T00:26:49.314485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14440, 76)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_A</th>\n",
       "      <th>0_C</th>\n",
       "      <th>0_G</th>\n",
       "      <th>0_T</th>\n",
       "      <th>1_A</th>\n",
       "      <th>1_C</th>\n",
       "      <th>1_G</th>\n",
       "      <th>1_T</th>\n",
       "      <th>2_A</th>\n",
       "      <th>2_C</th>\n",
       "      <th>...</th>\n",
       "      <th>16_G</th>\n",
       "      <th>17_A</th>\n",
       "      <th>17_C</th>\n",
       "      <th>17_G</th>\n",
       "      <th>18_A</th>\n",
       "      <th>18_C</th>\n",
       "      <th>18_G</th>\n",
       "      <th>19_A</th>\n",
       "      <th>19_C</th>\n",
       "      <th>19_G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_A  0_C  0_G  0_T  1_A  1_C  1_G  1_T  2_A  2_C  ...  16_G  17_A  17_C  \\\n",
       "0    0    0    1    0    0    0    1    0    1    0  ...     1     1     0   \n",
       "1    0    0    1    0    0    0    1    0    0    1  ...     0     1     0   \n",
       "2    0    0    0    1    1    0    0    0    1    0  ...     0     0     1   \n",
       "3    1    0    0    0    0    0    1    0    0    0  ...     1     0     0   \n",
       "4    0    0    1    0    1    0    0    0    0    0  ...     0     1     0   \n",
       "\n",
       "   17_G  18_A  18_C  18_G  19_A  19_C  19_G  \n",
       "0     0     0     0     1     0     1     0  \n",
       "1     0     0     0     1     0     0     1  \n",
       "2     0     0     0     1     1     0     0  \n",
       "3     1     1     0     0     0     1     0  \n",
       "4     0     0     1     0     1     0     0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_array_1hot = pd.get_dummies(seq_array)\n",
    "print(seq_array_1hot.shape)\n",
    "seq_array_1hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cooked-firmware",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T00:26:49.379429Z",
     "start_time": "2021-09-28T00:26:49.375634Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0_A', '0_C', '0_G', '0_T', '1_A', '1_C', '1_G', '1_T', '2_A',\n",
       "       '2_C', '2_G', '2_T', '3_A', '3_C', '3_G', '3_T', '4_A', '4_C',\n",
       "       '4_G', '4_T', '5_A', '5_C', '5_G', '5_T', '6_A', '6_C', '6_G',\n",
       "       '6_T', '7_A', '7_C', '7_G', '7_T', '8_A', '8_C', '8_G', '8_T',\n",
       "       '9_A', '9_C', '9_G', '9_T', '10_A', '10_C', '10_G', '10_T', '11_A',\n",
       "       '11_C', '11_G', '11_T', '12_A', '12_C', '12_G', '12_T', '13_A',\n",
       "       '13_C', '13_G', '13_T', '14_A', '14_C', '14_G', '14_T', '15_A',\n",
       "       '15_C', '15_G', '15_T', '16_A', '16_C', '16_G', '17_A', '17_C',\n",
       "       '17_G', '18_A', '18_C', '18_G', '19_A', '19_C', '19_G'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_array_1hot.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "featured-spanish",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T00:26:49.387270Z",
     "start_time": "2021-09-28T00:26:49.381111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C    6780\n",
       "A    4180\n",
       "G    3480\n",
       "Name: 19, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_array[19].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dedicated-variable",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T00:26:49.395454Z",
     "start_time": "2021-09-28T00:26:49.389169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C    5665\n",
       "A    4475\n",
       "G    4300\n",
       "Name: 18, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_array[18].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-signal",
   "metadata": {},
   "source": [
    "OK, so the missing T's in the end of the guide appear to be missing from the data.  Let's re-index it to add those in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "designing-capacity",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T00:26:49.418188Z",
     "start_time": "2021-09-28T00:26:49.397956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0_A', '0_C', '0_G', '0_T', '1_A', '1_C', '1_G', '1_T', '2_A', '2_C', '2_G', '2_T', '3_A', '3_C', '3_G', '3_T', '4_A', '4_C', '4_G', '4_T', '5_A', '5_C', '5_G', '5_T', '6_A', '6_C', '6_G', '6_T', '7_A', '7_C', '7_G', '7_T', '8_A', '8_C', '8_G', '8_T', '9_A', '9_C', '9_G', '9_T', '10_A', '10_C', '10_G', '10_T', '11_A', '11_C', '11_G', '11_T', '12_A', '12_C', '12_G', '12_T', '13_A', '13_C', '13_G', '13_T', '14_A', '14_C', '14_G', '14_T', '15_A', '15_C', '15_G', '15_T', '16_A', '16_C', '16_G', '17_A', '17_C', '17_G', '18_A', '18_C', '18_G', '19_A', '19_C', '19_G', '16_T', '17_T', '18_T', '19_T']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_A</th>\n",
       "      <th>0_C</th>\n",
       "      <th>0_G</th>\n",
       "      <th>0_T</th>\n",
       "      <th>1_A</th>\n",
       "      <th>1_C</th>\n",
       "      <th>1_G</th>\n",
       "      <th>1_T</th>\n",
       "      <th>2_A</th>\n",
       "      <th>2_C</th>\n",
       "      <th>...</th>\n",
       "      <th>18_A</th>\n",
       "      <th>18_C</th>\n",
       "      <th>18_G</th>\n",
       "      <th>19_A</th>\n",
       "      <th>19_C</th>\n",
       "      <th>19_G</th>\n",
       "      <th>16_T</th>\n",
       "      <th>17_T</th>\n",
       "      <th>18_T</th>\n",
       "      <th>19_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_A  0_C  0_G  0_T  1_A  1_C  1_G  1_T  2_A  2_C  ...  18_A  18_C  18_G  \\\n",
       "0    0    0    1    0    0    0    1    0    1    0  ...     0     0     1   \n",
       "1    0    0    1    0    0    0    1    0    0    1  ...     0     0     1   \n",
       "2    0    0    0    1    1    0    0    0    1    0  ...     0     0     1   \n",
       "3    1    0    0    0    0    0    1    0    0    0  ...     1     0     0   \n",
       "4    0    0    1    0    1    0    0    0    0    0  ...     0     1     0   \n",
       "\n",
       "   19_A  19_C  19_G  16_T  17_T  18_T  19_T  \n",
       "0     0     1     0     0     0     0     0  \n",
       "1     0     0     1     0     0     0     0  \n",
       "2     1     0     0     0     0     0     0  \n",
       "3     0     1     0     0     0     0     0  \n",
       "4     1     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cols = seq_array_1hot.columns.values.tolist() + ['16_T', '17_T', '18_T', '19_T']\n",
    "print(new_cols)\n",
    "seq_array_1hot = seq_array_1hot.reindex(columns =  new_cols, fill_value=0)\n",
    "seq_array_1hot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-european",
   "metadata": {},
   "source": [
    "To control for variable gene effect sizes I'll include a gene indicator.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "informational-passenger",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T00:26:49.442303Z",
     "start_time": "2021-09-28T00:26:49.420720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14440, 321)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_ACTL6A</th>\n",
       "      <th>gene_ACTR6</th>\n",
       "      <th>gene_ALYREF</th>\n",
       "      <th>gene_ANAPC4</th>\n",
       "      <th>gene_ANAPC5</th>\n",
       "      <th>gene_AP2S1</th>\n",
       "      <th>gene_AQR</th>\n",
       "      <th>gene_ARCN1</th>\n",
       "      <th>gene_ARL5B</th>\n",
       "      <th>gene_ATP6V0D1</th>\n",
       "      <th>...</th>\n",
       "      <th>gene_XIAP</th>\n",
       "      <th>gene_XPO1</th>\n",
       "      <th>gene_YY1</th>\n",
       "      <th>gene_ZBTB48</th>\n",
       "      <th>gene_ZC3H13</th>\n",
       "      <th>gene_ZC3H18</th>\n",
       "      <th>gene_ZFR</th>\n",
       "      <th>gene_ZNF160</th>\n",
       "      <th>gene_ZNF207</th>\n",
       "      <th>gene_chr10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 321 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gene_ACTL6A  gene_ACTR6  gene_ALYREF  gene_ANAPC4  gene_ANAPC5  gene_AP2S1  \\\n",
       "0            1           0            0            0            0           0   \n",
       "1            1           0            0            0            0           0   \n",
       "2            1           0            0            0            0           0   \n",
       "3            1           0            0            0            0           0   \n",
       "4            1           0            0            0            0           0   \n",
       "\n",
       "   gene_AQR  gene_ARCN1  gene_ARL5B  gene_ATP6V0D1  ...  gene_XIAP  gene_XPO1  \\\n",
       "0         0           0           0              0  ...          0          0   \n",
       "1         0           0           0              0  ...          0          0   \n",
       "2         0           0           0              0  ...          0          0   \n",
       "3         0           0           0              0  ...          0          0   \n",
       "4         0           0           0              0  ...          0          0   \n",
       "\n",
       "   gene_YY1  gene_ZBTB48  gene_ZC3H13  gene_ZC3H18  gene_ZFR  gene_ZNF160  \\\n",
       "0         0            0            0            0         0            0   \n",
       "1         0            0            0            0         0            0   \n",
       "2         0            0            0            0         0            0   \n",
       "3         0            0            0            0         0            0   \n",
       "4         0            0            0            0         0            0   \n",
       "\n",
       "   gene_ZNF207  gene_chr10  \n",
       "0            0           0  \n",
       "1            0           0  \n",
       "2            0           0  \n",
       "3            0           0  \n",
       "4            0           0  \n",
       "\n",
       "[5 rows x 321 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_one_hot = pd.get_dummies(essential_data['gene'], prefix = 'gene')\n",
    "print(gene_one_hot.shape)\n",
    "gene_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acquired-cache",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T00:26:49.463126Z",
     "start_time": "2021-09-28T00:26:49.444874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14440, 401)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = seq_array_1hot.merge(gene_one_hot, left_index = True, right_index = True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "framed-pilot",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T00:26:49.469176Z",
     "start_time": "2021-09-28T00:26:49.465584Z"
    }
   },
   "outputs": [],
   "source": [
    "y = essential_data['log2FoldChange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "identified-cardiff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T00:56:35.366990Z",
     "start_time": "2021-09-28T00:56:35.364113Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error,explained_variance_score\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-expansion",
   "metadata": {},
   "source": [
    "## Simple train-test split\n",
    "\n",
    "First, let's look at a simple train-test split.  Since there's 5 libraries/data sources, I'll do a 20% test set size. Note that the training data is evenly split by library, so taking a standard Cv split results in a split by library.  I'll shuffle the data frame before computing the CV scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "blocked-scheme",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T00:58:25.827640Z",
     "start_time": "2021-09-28T00:56:36.364774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.301244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.292186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.294729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.305585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.353741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shuffled_df = X.copy()\n",
    "shuffled_df['y'] = y.copy()\n",
    "shuffled_df = shuffled_df.sample(frac=1, replace=False).reset_index(drop=True)\n",
    "shuffled_y = shuffled_df['y']\n",
    "shuffled_X = shuffled_df.drop(['y'], axis = 1)\n",
    "rf_model = RandomForestRegressor()\n",
    "cv_scores = cross_val_score(rf_model, shuffled_X, shuffled_y, cv=5)\n",
    "cv_scores = pd.DataFrame({'cv': [1, 2, 3, 4, 5],\n",
    "                          'score': cv_scores})\n",
    "display(HTML(cv_scores.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "demanding-detector",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T00:58:26.349293Z",
     "start_time": "2021-09-28T00:58:26.343899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3094969079470874"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "novel-boutique",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T01:12:14.224560Z",
     "start_time": "2021-09-28T01:12:14.220629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025291677941089247"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores['score'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-leisure",
   "metadata": {},
   "source": [
    "## Split by library\n",
    "\n",
    "Now let's take a look at what happens when you split by library. Note that since the libraries are in order, and there are an equal number of guides per library, we can do a standard 5-way cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "renewable-superior",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T01:00:16.372246Z",
     "start_time": "2021-09-28T00:58:26.760115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lib</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DLD1</td>\n",
       "      <td>0.467550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GBM</td>\n",
       "      <td>0.495323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HCT116_1</td>\n",
       "      <td>0.324966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HeLa</td>\n",
       "      <td>-0.277358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RPE1</td>\n",
       "      <td>0.352164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor()\n",
    "lib_cv_scores = cross_val_score(rf_model, X, y, cv=5)\n",
    "lib_cv_scores = pd.DataFrame({'lib': essential_data['lib'].unique(),\n",
    "                              'score': lib_cv_scores})\n",
    "display(HTML(lib_cv_scores.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "broad-testimony",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T01:00:16.771503Z",
     "start_time": "2021-09-28T01:00:16.767605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27252887076614246"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib_cv_scores['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "threatened-coating",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T01:12:23.258668Z",
     "start_time": "2021-09-28T01:12:23.254740Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.315886687365281"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib_cv_scores['score'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-egypt",
   "metadata": {},
   "source": [
    "# Interpretation\n",
    "\n",
    "Note that the average $R^{2}$ (the default score for `RandomForestRegressor`) is lower when split by library.  However, variance is higher, which results in the test set performance being high for some libraries. The order of the cell types are as follows:\n",
    "- DLD1, [male colorectal cancer cell line](https://www.atcc.org/products/ccl-221);\n",
    "- GBM, glioblastoma (don't know the exact cell line);\n",
    "- HCT116, [male colorectal carcinoma cell line](https://imanislife.com/collections/cell-lines/hct116-cells/);\n",
    "- HeLa, [female cervical cancer](https://en.wikipedia.org/wiki/HeLa);\n",
    "- RPE1, [female immortalized retinal pigment epithelium](https://web.expasy.org/cellosaurus/CVCL_4388).\n",
    "\n",
    "Note that the first two have the highest test set scores.  It seems reasonable that DLD1 and HCT116 would be highly predictive of each other, since they are similar cell types.  And it is reasonable that HeLa is very difficult to predict, since the karyotype of HeLa is completely haywire.  But what we're missing is the metadata, such as specific experimental design and who prepared the libraries.  In my experience, such details are crucial to evaluating the quality of a sequencing-based experiment.  When reserchers outside the organization use a publicly available ML tool, then the person preparing the experiment will (with exceedingly high probability) be new (to the ML tool).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-india",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-parking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crispy_code",
   "language": "python",
   "name": "crispy_code"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
