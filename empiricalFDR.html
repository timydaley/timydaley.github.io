<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Timothy Daley" />

<meta name="date" content="2020-12-27" />

<title>Empirical estimation of FDR</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/yeti.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="site_libs/anchor-sections-1.0/anchor-sections.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 45px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h2 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h3 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h4 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h5 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h6 {
  padding-top: 50px;
  margin-top: -50px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">HOME</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="FisherVsStouffer.html">Fisher vs Stouffer</a>
</li>
<li>
  <a href="twoGroupsBackground.html">2 groups</a>
</li>
<li>
  <a href="empiricalFDR.html">empirical estimation of FDRs</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Empirical estimation of FDR</h1>
<h4 class="author">Timothy Daley</h4>
<h4 class="date">12/27/2020</h4>

</div>


<div id="a-brief-introduction-to-the-theory-of-local-and-global-false-discovery-rates" class="section level1">
<h1>A brief introduction to the theory of local and global False Discovery Rates</h1>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>A more detailed explanation is given in a my previous post <a href="https://timydaley.github.io/twoGroupsBackground.html">Background of two groups model</a>.</p>
<p>An idea I put into package CRISPhieRmix (<a href="https://github.com/timydaley/CRISPhieRmix">R package</a>, <a href="https://genomebiology.biomedcentral.com/articles/10.1186/s13059-018-1538-6">paper</a>) is a way to estimate global false discovery rates (FDRs) from local fdrs when it is too difficult to directly compute the global FDR.</p>
<p>The global FDR is the expected fraction of false discoveries among the ones that we call significant. The way we usually think about this is that we’re gonna compute some one dimensional statistic (e.g. <span class="math inline">\(p\)</span>-value or <span class="math inline">\(z\)</span>-value) for tests/categories/hypotheses <span class="math inline">\(i = 1, \ldots, n\)</span>, we’re gonna set a threshold <span class="math inline">\(p^{*}\)</span> (or <span class="math inline">\(z^{*}\)</span> if we look in terms of a <span class="math inline">\(z\)</span>-value), then we’re gonna call as significant those with <span class="math inline">\(p_{i} &lt; p^{*}\)</span> (or <span class="math inline">\(| z_{i} | &gt; z^{*}\)</span>). Then the expected fraction of false discoveries among the set that we called significant is the global FDR, or <span class="math display">\[
\mathrm{E} \left( \sum_{i = 1}^{n} 1 \left( \text{test } i \text{ is null}  \cap p_{i} &lt; p^{*} \right) / \sum_{i=1}^{n} 1 \left(p_{i} &lt; p^{*} \right) \right).
\]</span> Note that there is some difficulty in defining the FDR when no tests are called significant. To get around this difficulty we can define marginal FDR (mFDR) as the ratio of the expected number of nulls called significant divided by the expected number of tests called significant, with the understanding that <span class="math inline">\(0/0 = 0\)</span> (see <a href="http://theta.edu.pl/wp-content/uploads/2012/10/Storey_FDR_2010.pdf">Storey, 2010</a>). I.e. <span class="math display">\[
\text{mFDR} = \frac{\mathrm{E} \big( \sum_{i = 1}^{n} 1 \left( \text{test } i \text{ is null}  \cap p_{i} &lt; p^{*} \right) \big)}{\mathrm{E} \big( \sum_{i = 1}^{n} 1(p_{i} &lt; p^{*}) \big)}.
\]</span></p>
<p>Similarly, the local fdr (following <a href="https://pdfs.semanticscholar.org/93dd/1ad905da7b09568aaf7d04c3d325772d42fc.pdf">Efron’s notation</a> of keeping the local fdr in lower case) is the expected probability that an individual test is false. So for example, for test <span class="math inline">\(i\)</span> we get <span class="math inline">\(p\)</span>-value <span class="math inline">\(p_{i}\)</span> then the local fdr is <span class="math display">\[
\Pr(\text{test } i \text{ is null} | p_{i}).
\]</span></p>
</div>
<div id="empirical-estimation-of-the-global-fdr" class="section level2">
<h2>Empirical estimation of the global FDR</h2>
<p>The idea for empirical estimation came from an anology from <a href="https://pdfs.semanticscholar.org/93dd/1ad905da7b09568aaf7d04c3d325772d42fc.pdf">Efron, 2005</a>, the local false discovery rate is akin to the pdf and the global FDR is akin the cdf. We can see this from the (rather loose) definitions given above. Indeed, formally the global false discovery rates can be defined as the integral over the tail area of the local false discovery rates, as well as the intuition that the overall (global) FDR at a given threshold must be equal to the average of the individual local FDRs that are called significant at the threshold.</p>
<p>This intuition leads directly to the an easy way to estimate the global FDRs when we have the local fdrs, we just take the average of all local fdr’s lower than the one under consideration to be the estimate of the global FDR. In fact, this is an unbiased estimate of the marginal false discovery rate.</p>
<p>We’ll show this in the 1-dimensional case. For a measurement <span class="math inline">\(x\)</span>, we assume that the measurements follow a mixture distribution with <span class="math inline">\(x \sim f = (1- p) f_{0} + p f_{1}\)</span>. <span class="math inline">\(p\)</span> is the probability that a randomly selected test will be non-null, <span class="math inline">\(f_{0}\)</span> is the distribution of null cases, and <span class="math inline">\(f_{1}\)</span> is the distribution of non-null cases. <span class="math display">\[
\begin{aligned}
\text{mFDR}(x) &amp;\approx \frac{\mathrm{E} \big( \sum_{i = 1}^{n} 1(x_{i} \geq x \cap \text{ test } i \text{ is null}) \big)}{\mathrm{E} \big( \sum_{i = 1}^{n} 1(x_{i} \geq x) \big)} 
\notag \\
&amp;= \frac{\int_{|z| \geq x} (1 - p) f_{0} (z) dz }{\int_{|z| &gt; x} f(z) dz}
\notag \\
&amp;= \frac{\int_{|z| \geq x} \frac{(1 - p) f_{0} (z)}{f(z)} f(z) dz}{\int_{|z| \geq x} f(z) dz} .
\notag \\
&amp; = \frac{\mathrm{E} \big(\text{fdr}(z) \cdot 1(|z| \geq x) \big)}{\mathrm{E} \big( 1(|z| \geq x) \big)}
\notag \\
&amp;\approx \frac{\frac{1}{N} \sum_{i = 1}^{n} \text{fdr}(x_{i}) 1 (\text{fdr}(x_{i}) \leq \text{fdr}(x))}{\frac{1}{N} \sum_{i = 1}^{n} 1 (\text{fdr}(x_{i}) \leq \text{fdr}(x))}. 
\notag \\
&amp;
\notag
\end{aligned}
\]</span></p>
<p>The advantage for this method is that in some cases the local FDR is easy to compute but the global FDR is difficult. Such I case I encountered in my hierarchical mixture modeling of pooled CRISPR screens. Computing the global FDRs here involves integration over the level sets of a mixture model, which can be difficult. Below is an example of the level sets for when we have 2 guides (measurements) per gene, more guides makes it even more complicated. [levelSets2D.png]</p>
</div>
</div>
<div id="simulations" class="section level1">
<h1>Simulations</h1>
<div id="d-case" class="section level2">
<h2>1-D case</h2>
<p>The simplest case is the one dimensional case. We’ll assume that we have a normal mixture model, <span class="math display">\[
f(x) \sim (1 - p) \mathcal{N}(0, \sigma_{0}^2) + p \mathcal{N}(\mu, \sigma_{1}^{2}).
\]</span> We’ll compare two cases, fitting the mixture model and computing the local FDR and global FDR from the empirical method, and the exact method (because it’s easy to compute in this case).</p>
<pre class="r"><code>set.seed(12345)
mu0 = 0
mu1 = 3
sigma0 = 1
sigma1 = 1
p = 0.95
N = 10000
labels = rbinom(N, prob = 1 - p, 1)
mu_vec = sapply(labels, function(i) if(i == 1) mu1 else mu0)
sigma_vec = sapply(labels, function(i) if(i == 1) sigma1 else sigma0)
# sanity check
stopifnot(sum(mu_vec != 0)/length(mu_vec) == sum(labels)/length(labels))
x = rnorm(N, mean = mu_vec, sd = sigma_vec)</code></pre>
<pre class="r"><code>mixfit = mixtools::normalmixEM2comp(x, lambda = c(0.5, 0.5), 
                                    mu = c(0, 1), sigsqrd = c(1, 1))</code></pre>
<pre><code>## number of iterations= 1000</code></pre>
<pre class="r"><code>print(&quot;fitted proportions: &quot;)</code></pre>
<pre><code>## [1] &quot;fitted proportions: &quot;</code></pre>
<pre class="r"><code>print(mixfit$lambda)</code></pre>
<pre><code>## [1] 0.94405034 0.05594966</code></pre>
<pre class="r"><code>print(&quot;fitted means: &quot;)</code></pre>
<pre><code>## [1] &quot;fitted means: &quot;</code></pre>
<pre class="r"><code>print(mixfit$mu)</code></pre>
<pre><code>## [1] -0.008031135  2.656248538</code></pre>
<pre class="r"><code>print(&quot;fitted sd&#39;s: &quot;)</code></pre>
<pre><code>## [1] &quot;fitted sd&#39;s: &quot;</code></pre>
<pre class="r"><code>print(mixfit$sigma)</code></pre>
<pre><code>## [1] 0.9948498 1.1280971</code></pre>
<pre class="r"><code># taken from https://tinyheero.github.io/2015/10/13/mixture-model.html
plot_mix_comps &lt;- function(x, mu, sigma, lam) {
  lam * dnorm(x, mu, sigma)
}
library(ggplot2)
ggplot(data.frame(x = x) ) +
  geom_histogram(aes(x, ..density..), binwidth = 1, colour = &quot;black&quot;, 
                 fill = &quot;white&quot;) +
  stat_function(geom = &quot;line&quot;, fun = plot_mix_comps,
                args = list(mixfit$mu[1], mixfit$sigma[1], lam = mixfit$lambda[1]),
                colour = &quot;red&quot;, lwd = 1.5) +
  stat_function(geom = &quot;line&quot;, fun = plot_mix_comps,
                args = list(mixfit$mu[2], mixfit$sigma[2], lam = mixfit$lambda[2]),
                colour = &quot;blue&quot;, lwd = 1.5) +
  ylab(&quot;Density&quot;) + theme_bw()</code></pre>
<p><img src="empiricalFDR_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>The local FDR here is easy to compute, <span class="math display">\[
\Pr(i \text{ is null} | x_{i}) = \frac{p f_{1} (x_{i} | \mu_{1}, \sigma_{1})}{(1 - p) f_{0}(x_{i} | \mu_{0}, \sigma_{0}) + p f_{1} (x_{i} | \mu_{1}, \sigma_{1})}.
\]</span> Similarly the global mFDR is equal to <span class="math display">\[
mFDR(i) = \frac{\int_{x \geq x_{i}} p f_{1} (x | \mu_{1}, \sigma_{1}) dx}{\int_{x \geq x_{i}} (1 - p) f_{0}(x | \mu_{0}, \sigma_{0}) + p f_{1} (x | \mu_{1}, \sigma_{1}) dx}.
\]</span> Of course, the global FDR (not marginal) has the integral outside the fraction above, but the above equation is much easier to compute because the integrals can be calculated from the cdf of the normal distribution.</p>
<pre class="r"><code>normal_2group_loc_fdr &lt;- function(x, p, mu, sigma){
  # the assumption here is that the null group is the second group
  stopifnot((length(p) == length(mu)) &amp;
            (length(mu) == length(sigma)) &amp;
            (length(sigma) == 2))
  p0 = p[1]*dnorm(x, mu[1], sigma[1])
  p1 = p[2]*dnorm(x, mu[2], sigma[2])
  return(p1/(p0 + p1))
}

normal_2group_mFDR &lt;- function(x, p, mu, sigma){
  # the assumption here is that the null group is the second group
  stopifnot((length(p) == length(mu)) &amp;
            (length(mu) == length(sigma)) &amp;
            (length(sigma) == 2))
  p0 = p[1]*pnorm(x, mu[1], sigma[1], lower.tail = FALSE)
  p1 = p[2]*pnorm(x, mu[2], sigma[2], lower.tail = FALSE)
  return(p0/(p0 + p1))
}</code></pre>
<p>Now let’s compare the methods. For comparison we will also include the standard Benjamini-Hochberg correct p-value method of computing FDRs.</p>
<pre class="r"><code>BH_FDR &lt;- function(x, mu0, sigma0){
  pvals = sapply(x, function(y) pnorm(y, mu0, sigma0, lower.tail = FALSE))
  return(p.adjust(pvals, method = &quot;BH&quot;))
}

compare_fdr &lt;- function(x, p, mu, sigma, labels){
  loc_fdr = sapply(x, function(y) normal_2group_loc_fdr(y, p, mu, sigma))
  loc_mFDR = sapply(x, function(y) mean(loc_fdr[which(x &gt;= y)]))
  mFDR = sapply(x, function(y) normal_2group_mFDR(y, p, mu, sigma))
  bh = BH_FDR(x, mu[1], sigma[1])
  true_fdr = sapply(1:length(x), function(i) sum(labels[which(x &gt;= x[i])] == 0)/length(which(x &gt;= x[i])))
  return(data.frame(x = x,
                    loc_fdr = loc_fdr,
                    loc_mFDR = 1 - loc_mFDR,
                    mFDR = mFDR,
                    BH_FDR = bh,
                    true_FDR = true_fdr))
}

normal_2_group_fdr_comparison = compare_fdr(x, mixfit$lambda, mixfit$mu, mixfit$sigma, labels)</code></pre>
<pre class="r"><code>df = data.frame(estimated_fdr = c(normal_2_group_fdr_comparison$loc_mFDR, 
                                  normal_2_group_fdr_comparison$mFDR, 
                                  normal_2_group_fdr_comparison$BH_FDR), 
                method = rep(c(&quot;loc_mFDR&quot;, &quot;mFDR&quot;, &quot;BH&quot;), each = N),
                true_fdr = rep(normal_2_group_fdr_comparison$true_FDR, times = 3))
ggplot(df, aes(y = true_fdr, x = estimated_fdr, col = method)) + geom_line() + scale_colour_brewer(palette = &quot;Set1&quot;) + theme_bw() + geom_abline(intercept = 0, slope = 1)</code></pre>
<p><img src="empiricalFDR_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>The empirical method is on-par with exact method, though the Benjamini-Hochberg FDRs show slightly better calibration with the true FDR.</p>
</div>
<div id="multi-dimensional-case" class="section level2">
<h2>Multi-dimensional case</h2>
<p>Let’s now take a look at the hierarchical model. We’ll assume that each test/gene have 5 measurements, and the measurements for the non-null genes also follow a mixture distribution, e.g. <span class="math inline">\(f_{1} = (1 - q) f_{0} + q f_{2}\)</span>. This creates more uncertainty about the true positives.</p>
<pre class="r"><code>set.seed(12345)
n_genes = 10000
n_guides_per_gene = 5
genes = rep(1:n_genes, each = n_guides_per_gene)
x = rep(0, times = length(genes))
mu0 = 0
mu1 = 2
sigma0 = 1
sigma1 = 1
p_gene = 0.9
p_guide = 0.5
gene_labels = rbinom(n_genes, prob = 1 - p_gene, 1)
for(i in 1:n_genes){
  if(gene_labels[i] == 0){
    x[which(genes == i)] = rnorm(n_guides_per_gene, mean = mu0, sd = sigma0)
  }
  else{
    # gene label == 1
    guide_labels = rbinom(n_guides_per_gene, prob = 1 - p_guide, 1)
    mu_vec = sapply(guide_labels, function(i) if(i == 1) mu1 else mu0)
    sigma_vec = sapply(guide_labels, function(i) if(i == 1) sigma1 else sigma0)
    x[which(genes == i)] = rnorm(n_guides_per_gene, mean = mu_vec, sd = sigma_vec)
  }
}</code></pre>
<pre class="r"><code>mixfit = mixtools::normalmixEM2comp(x, lambda = c(0.5, 0.5), 
                                    mu = c(0, 1), sigsqrd = c(1, 1))</code></pre>
<pre><code>## number of iterations= 1000</code></pre>
<pre class="r"><code>print(&quot;fitted proportions: &quot;)</code></pre>
<pre><code>## [1] &quot;fitted proportions: &quot;</code></pre>
<pre class="r"><code>print(mixfit$lambda)</code></pre>
<pre><code>## [1] 0.8075129 0.1924871</code></pre>
<pre class="r"><code>print(&quot;fitted means: &quot;)</code></pre>
<pre><code>## [1] &quot;fitted means: &quot;</code></pre>
<pre class="r"><code>print(mixfit$mu)</code></pre>
<pre><code>## [1] -0.05286371  0.72474277</code></pre>
<pre class="r"><code>print(&quot;fitted sd&#39;s: &quot;)</code></pre>
<pre><code>## [1] &quot;fitted sd&#39;s: &quot;</code></pre>
<pre class="r"><code>print(mixfit$sigma)</code></pre>
<pre><code>## [1] 0.9720461 1.3047024</code></pre>
<pre class="r"><code># taken from https://tinyheero.github.io/2015/10/13/mixture-model.html
plot_mix_comps &lt;- function(x, mu, sigma, lam) {
  lam * dnorm(x, mu, sigma)
}
library(ggplot2)
ggplot(data.frame(x = x) ) +
  geom_histogram(aes(x, ..density..), binwidth = 1, colour = &quot;black&quot;, 
                 fill = &quot;white&quot;) +
  stat_function(geom = &quot;line&quot;, fun = plot_mix_comps,
                args = list(mixfit$mu[1], mixfit$sigma[1], lam = mixfit$lambda[1]),
                colour = &quot;red&quot;, lwd = 1.5) +
  stat_function(geom = &quot;line&quot;, fun = plot_mix_comps,
                args = list(mixfit$mu[2], mixfit$sigma[2], lam = mixfit$lambda[2]),
                colour = &quot;blue&quot;, lwd = 1.5) +
  ylab(&quot;Density&quot;) + theme_bw()</code></pre>
<p><img src="empiricalFDR_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>The hierarchical mixture model has likelihood (see the Methods section of <a href="https://link.springer.com/article/10.1186/s13059-018-1538-6" class="uri">https://link.springer.com/article/10.1186/s13059-018-1538-6</a>) <span class="math display">\[
\mathcal{L}(f_{0}, f_{1}, p, q | x_{1}, \ldots, x_{n}) = \prod_{g = 1}^{G} (1 - p) \prod_{i: g_{i} = g} f_{0} (x_{i}) + p \prod_{i : g_{i} = g} \big( (1 - q) f_{0} (x_{i}) + q f_{1} (x_{i}) \big).
\]</span> Because of the non-identifiability of <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span> simultaneously, we marginalized over <span class="math inline">\(q\)</span> (with a uniform prior) to obtain gene-level local false discovery rates <span class="math display">\[
\text{locfdr}(g) = \int_{0}^{1} \frac{(\hat{\tau} / q) \prod_{i: g_{i} = g} q f_{1} (x_{i}) + (1 - q) f_{0} (x_{i}) }{(\hat{\tau} / q) \prod_{i: g_{i} = g} \big(  q f_{1} (x_{i}) + (1 - q) f_{0} (x_{i})  \big) + (1 - \hat{\tau} / q) \prod_{i: g_{i} = g} f_{0} (x_{i})} d q.
\]</span> We then used the empirical FDR estimator to compute estimates for the global false discovery rates.</p>
<pre class="r"><code>crisphiermixFit = CRISPhieRmix::CRISPhieRmix(x = x, geneIds = genes, 
                                             pq = 0.1, mu = 4, sigma = 1,
                                             nMesh = 100,  BIMODAL = FALSE,
                                             VERBOSE = TRUE, PLOT = TRUE,
                                             screenType = &quot;GOF&quot;)</code></pre>
<pre><code>## no negative controls provided, fitting hierarchical normal model</code></pre>
<pre><code>## Loading required package: mixtools</code></pre>
<pre><code>## mixtools package, version 1.2.0, Released 2020-02-05
## This package is based upon work supported by the National Science Foundation under Grant No. SES-0518772.</code></pre>
<pre><code>## WARNING! NOT CONVERGENT! 
## number of iterations= 1000</code></pre>
<p><img src="empiricalFDR_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code>crisphiermixFit$mixFit$lambda</code></pre>
<pre><code>## [1] 0.95278182 0.04721818</code></pre>
<pre class="r"><code>crisphiermixFit$mixFit$mu</code></pre>
<pre><code>## [1] 0.004446553 1.960693489</code></pre>
<pre class="r"><code>crisphiermixFit$mixFit$sigma</code></pre>
<pre><code>## [1] 1.005094 1.028718</code></pre>
<pre class="r"><code>null_pvals = sapply(1:n_genes, function(g) t.test(x[which(genes == g)], alternative = &quot;greater&quot;, mu = crisphiermixFit$mixFit$mu[1])$p.value)
bh_fdr = data.frame(estimated_FDR = p.adjust(null_pvals, method = &quot;fdr&quot;),
                    pvals = null_pvals)
bh_fdr[&#39;true_fdr&#39;] = sapply(bh_fdr$estimated_FDR, function(p) sum(gene_labels[which(bh_fdr$estimated_FDR &lt;= p)] == 0)/sum(bh_fdr$estimated_FDR &lt;= p))
head(bh_fdr)</code></pre>
<pre><code>##   estimated_FDR     pvals  true_fdr
## 1     0.9795228 0.8252480 0.8871217
## 2     0.9390381 0.5319651 0.8395410
## 3     0.9797612 0.8294592 0.8880518
## 4     0.9857013 0.8827119 0.8933676
## 5     0.9470087 0.6006585 0.8558586
## 6     0.7356476 0.1166486 0.6505949</code></pre>
<pre class="r"><code>crisphiermixFDR = data.frame(estimated_FDR = crisphiermixFit$FDR)
crisphiermixFDR[&#39;true_fdr&#39;] = sapply(crisphiermixFDR$estimated_FDR, function(p) sum(gene_labels[which(crisphiermixFDR$estimated_FDR &lt;= p)] == 0)/sum(crisphiermixFDR$estimated_FDR &lt;= p))
head(crisphiermixFDR)</code></pre>
<pre><code>##   estimated_FDR  true_fdr
## 1     0.8063019 0.8621093
## 2     0.8068114 0.8626709
## 3     0.8352201 0.8919991
## 4     0.8385534 0.8952391
## 5     0.7792940 0.8341960
## 6     0.6835582 0.7305573</code></pre>
<pre class="r"><code>cols = RColorBrewer::brewer.pal(8, &#39;Set1&#39;)
df = data.frame(estimated_FDR = c(crisphiermixFDR$estimated_FDR, bh_fdr$estimated_FDR),
                true_FDR = c(crisphiermixFDR$true_fdr, bh_fdr$true_fdr),
                method = rep(c(&quot;empirical FDR&quot;, &quot;BH FDR&quot;), each = dim(crisphiermixFDR)[1]))
ggplot(df, aes(y = true_FDR, x = estimated_FDR, col = method)) + geom_line() + theme_bw() + scale_colour_brewer(palette = &quot;Set1&quot;) + geom_abline(intercept = 0, slope = 1)</code></pre>
<p><img src="empiricalFDR_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>What’s happening with the Benjamini-Hochberg FDRs? Why aren’t many lower than 0.3?</p>
<pre class="r"><code>head(bh_fdr[which(bh_fdr$estimated_FDR &lt; 0.3), ])</code></pre>
<pre><code>##      estimated_FDR        pvals  true_fdr
## 20       0.2548441 0.0002241322 0.1764706
## 1069     0.2548441 0.0004236029 0.1764706
## 2342     0.2548441 0.0001856662 0.1764706
## 2750     0.2548441 0.0002576694 0.1764706
## 2897     0.2548441 0.0001255965 0.1764706
## 3433     0.2548441 0.0002680069 0.1764706</code></pre>
<p>We see that the Benjamini-Hochberg-corrected <span class="math inline">\(t\)</span>-test is not powerful enough to give meaningful insight into low false discovery rate region. Though, the rest of the region is well-calibrated. However, we see that the empirical estimator of the FDR is very well calibrated. At least in this case when the model is correctly specified. An argument could be made that the empirical estimator has the advantage of knowing the correct model, but that would lead the BH FDRs to not be calibrated and not what we see here.</p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
